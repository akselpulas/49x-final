# CE49X Final Project - Proje Ã–zeti ve KullanÄ±lan Kodlar

## Proje: Civil Engineering & AI Integration - Industry Trends Analysis

Bu dokÃ¼mantasyon, CE49X Final Project kapsamÄ±nda yapÄ±lan tÃ¼m iÅŸlemleri ve kullanÄ±lan scriptleri kronolojik olarak Ã¶zetlemektedir.

---

## ğŸ“‹ Ä°Ã§indekiler

1. [VeritabanÄ± Kurulumu (Database Setup)](#veritabani-kurulumu)
2. [Task 1: Data Collection (Veri Toplama)](#task-1-data-collection)
3. [Task 2: Text Preprocessing & NLP](#task-2-text-preprocessing--nlp)
   - [ğŸ“ NLP KÄ±smÄ±nÄ±n Konumu ve DetaylarÄ±](#-nlp-kÄ±smÄ±nÄ±n-konumu-ve-detaylarÄ±)
   - [ğŸ” NLP KISMI HIZLI REFERANS](#-nlp-kismi-hizli-referans)
4. [Task 3: Categorization & Trend Analysis](#task-3-categorization--trend-analysis)
5. [Task 4: Visualization & Insights](#task-4-visualization--insights)
6. [Database Management](#database-management)
7. [Final Data Preparation](#final-data-preparation)

---

## VeritabanÄ± Kurulumu

Bu projede verileri saklamak iÃ§in **PostgreSQL** adÄ±nda bir veritabanÄ± sistemi kullanÄ±ldÄ±. VeritabanÄ± kurulumu iÃ§in **Docker** adÄ±nda bir teknoloji kullanÄ±ldÄ±. Ä°ÅŸte hiÃ§ bilmeyen biri iÃ§in adÄ±m adÄ±m aÃ§Ä±klama:

### ğŸ³ Docker Nedir?

**Docker**, bilgisayarÄ±nÄ±zda sanal bir ortam oluÅŸturmanÄ±zÄ± saÄŸlayan bir araÃ§tÄ±r. TÄ±pkÄ± bir oyun konsolu gibi dÃ¼ÅŸÃ¼nebilirsiniz - oyun konsolunda oyunlar Ã§alÄ±ÅŸÄ±r, Docker'da ise uygulamalar (veritabanÄ± gibi) Ã§alÄ±ÅŸÄ±r.

**Neden Docker kullandÄ±k?**
- VeritabanÄ±nÄ± bilgisayarÄ±nÄ±za doÄŸrudan kurmak yerine, Docker iÃ§inde Ã§alÄ±ÅŸtÄ±rdÄ±k
- BÃ¶ylece bilgisayarÄ±nÄ±zÄ±n temiz kalmasÄ±nÄ± saÄŸladÄ±k
- Ä°stediÄŸimiz zaman aÃ§Ä±p kapatabiliriz
- BaÅŸka bilgisayarlarda da aynÄ± ÅŸekilde Ã§alÄ±ÅŸÄ±r

### ğŸ“¦ Kurulum AdÄ±mlarÄ±

#### AdÄ±m 1: Docker Desktop'Ä± Ä°ndirme ve Kurma

1. **Docker Desktop'Ä± indirin:** [https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)
2. **Kurulumu yapÄ±n:** Ä°ndirdiÄŸiniz dosyayÄ± Ã§alÄ±ÅŸtÄ±rÄ±n ve kurulum sihirbazÄ±nÄ± takip edin
3. **Docker'Ä± baÅŸlatÄ±n:** BilgisayarÄ±nÄ±zÄ± yeniden baÅŸlattÄ±ktan sonra Docker Desktop uygulamasÄ±nÄ± aÃ§Ä±n
4. **HazÄ±r olduÄŸunu kontrol edin:** Docker Desktop aÃ§Ä±ldÄ±ÄŸÄ±nda, sol Ã¼st kÃ¶ÅŸede "Docker Desktop is running" yazÄ±sÄ±nÄ± gÃ¶rmelisiniz

#### AdÄ±m 2: Proje KlasÃ¶rÃ¼ne Gitme

Terminal (komut satÄ±rÄ±) aÃ§Ä±n ve proje klasÃ¶rÃ¼ne gidin:

```bash
cd "C:\Users\Asus\Desktop\49X Final"
```

#### AdÄ±m 3: Docker Compose ile VeritabanÄ±nÄ± BaÅŸlatma

**Docker Compose nedir?** Birden fazla uygulamayÄ± (PostgreSQL + pgAdmin) birlikte Ã§alÄ±ÅŸtÄ±rmamÄ±zÄ± saÄŸlayan bir araÃ§tÄ±r.

Proje klasÃ¶rÃ¼nde `docker-compose.yml` adÄ±nda bir dosya var. Bu dosya, Docker'a ÅŸunu sÃ¶yler:
- PostgreSQL veritabanÄ±nÄ± baÅŸlat
- pgAdmin (veritabanÄ± yÃ¶netim arayÃ¼zÃ¼) uygulamasÄ±nÄ± baÅŸlat
- Ä°kisini birbirine baÄŸla

**Komut:**
```bash
docker-compose up -d
```

**Ne yapar?**
- `up`: UygulamalarÄ± baÅŸlat
- `-d`: Arka planda Ã§alÄ±ÅŸtÄ±r (detached mode)

**Beklenen Ã§Ä±ktÄ±:**
```
Creating network "49x-final_ce49x_network" ... done
Creating volume "49x-final_postgres_data" ... done
Creating ce49x_postgres ... done
Creating ce49x_pgadmin ... done
```

#### AdÄ±m 4: VeritabanÄ±nÄ±n HazÄ±r OlduÄŸunu Kontrol Etme

```bash
docker-compose ps
```

**Beklenen Ã§Ä±ktÄ±:**
```
NAME                STATUS          PORTS
ce49x_postgres      Up (healthy)    0.0.0.0:5432->5432/tcp
ce49x_pgadmin       Up               0.0.0.0:5050->80/tcp
```

Her iki servis de "Up" durumunda olmalÄ±.

### ğŸ—„ï¸ PostgreSQL Nedir?

**PostgreSQL**, verileri saklamak iÃ§in kullanÄ±lan bir veritabanÄ± sistemidir. Excel tablosu gibi dÃ¼ÅŸÃ¼nebilirsiniz, ama Ã§ok daha gÃ¼Ã§lÃ¼:

- **Excel:** Bir tabloda veri saklarsÄ±nÄ±z
- **PostgreSQL:** Birden fazla tabloda veri saklar, tablolar arasÄ± iliÅŸkiler kurar, hÄ±zlÄ± arama yapar

**Projemizde ne iÃ§in kullandÄ±k?**
- Toplanan makaleleri sakladÄ±k
- Makalelerin sÄ±nÄ±flandÄ±rma sonuÃ§larÄ±nÄ± sakladÄ±k
- Analiz sonuÃ§larÄ±nÄ± sakladÄ±k

### ğŸ›ï¸ pgAdmin4 Nedir?

**pgAdmin4**, PostgreSQL veritabanÄ±nÄ± gÃ¶rsel olarak yÃ¶netmek iÃ§in kullanÄ±lan bir web arayÃ¼zÃ¼dÃ¼r. Excel'i aÃ§Ä±p tablolarÄ± gÃ¶rmek gibi dÃ¼ÅŸÃ¼nebilirsiniz.

**NasÄ±l kullanÄ±lÄ±r?**

1. **TarayÄ±cÄ±da aÃ§Ä±n:** `http://localhost:5050`
2. **GiriÅŸ yapÄ±n:**
   - Email: `admin@ce49x.com`
   - Åifre: `admin`
3. **VeritabanÄ±na baÄŸlanÄ±n:**
   - Sol tarafta "Servers" Ã¼zerine saÄŸ tÄ±klayÄ±n
   - "Register" > "Server" seÃ§in
   - **General** sekmesi:
     - Name: `CE49X Database`
   - **Connection** sekmesi:
     - Host: `postgres` (Docker iÃ§indeki servis adÄ±)
     - Port: `5432`
     - Database: `ce49x_db`
     - Username: `ce49x_user`
     - Password: `ce49x_password`
   - "Save" butonuna tÄ±klayÄ±n

4. **TablolarÄ± gÃ¶rÃ¼ntÃ¼leyin:**
   - Sol tarafta `CE49X Database` > `Databases` > `ce49x_db` > `Schemas` > `public` > `Tables`
   - Burada tÃ¼m tablolarÄ± gÃ¶rebilirsiniz

### ğŸ“Š VeritabanÄ± YapÄ±sÄ±

Proje baÅŸladÄ±ÄŸÄ±nda, `database/init.sql` dosyasÄ± otomatik olarak Ã§alÄ±ÅŸtÄ±rÄ±ldÄ± ve ÅŸu tablolar oluÅŸturuldu:

1. **articles** - Toplanan makaleler
   - `id`: Makale numarasÄ±
   - `title`: BaÅŸlÄ±k
   - `url`: Makale linki
   - `content`: Ä°Ã§erik
   - vb.

2. **classifications** - LLM ile yapÄ±lan sÄ±nÄ±flandÄ±rmalar
   - `article_id`: Hangi makale
   - `ce_areas[]`: CE alanlarÄ± (Ã¶r: Structural, Transportation)
   - `ai_technologies[]`: AI teknolojileri (Ã¶r: Computer Vision, Predictive Analytics)
   - `confidence_score`: GÃ¼ven skoru

3. **all_valid_articles** - TÃ¼m valid makalelerin birleÅŸtirilmiÅŸ hali
   - NewsAPI, Guardian, Corpus kaynaklarÄ±ndan gelen valid makaleler
   - Final analiz iÃ§in kullanÄ±lan tablo

### ğŸ”§ VeritabanÄ± BaÄŸlantÄ± AyarlarÄ±

Python scriptlerinin veritabanÄ±na baÄŸlanabilmesi iÃ§in `.env` dosyasÄ± oluÅŸturuldu:

```env
# Database Settings
DB_HOST=localhost
DB_PORT=5432
DB_NAME=ce49x_db
DB_USER=ce49x_user
DB_PASSWORD=ce49x_password

# LLM API Keys
OPENAI_API_KEY=sk-your-key-here
```

**Neden `.env` dosyasÄ±?**
- Hassas bilgileri (ÅŸifreler, API anahtarlarÄ±) kod iÃ§inde saklamamak iÃ§in
- Herkes kendi bilgilerini ekleyebilir
- Git'e yÃ¼klenmez (`.gitignore` iÃ§inde)

### âœ… Kurulum KontrolÃ¼

VeritabanÄ±nÄ±n dÃ¼zgÃ¼n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol etmek iÃ§in:

```bash
python -c "from database.db_config import test_connection; print('âœ“ BaÄŸlantÄ± baÅŸarÄ±lÄ±!' if test_connection() else 'âœ— BaÄŸlantÄ± hatasÄ±!')"
```

**BaÅŸarÄ±lÄ± Ã§Ä±ktÄ±:** `âœ“ BaÄŸlantÄ± baÅŸarÄ±lÄ±!`

### ğŸ›‘ VeritabanÄ±nÄ± Durdurma

Ä°ÅŸiniz bittiÄŸinde veritabanÄ±nÄ± durdurmak iÃ§in:

```bash
docker-compose down
```

**Verileri de silmek isterseniz:**
```bash
docker-compose down -v
```

âš ï¸ **Dikkat:** `-v` parametresi tÃ¼m verileri siler!

### ğŸ“ Ã–zet

1. **Docker Desktop** kuruldu
2. **docker-compose up -d** komutuyla PostgreSQL ve pgAdmin baÅŸlatÄ±ldÄ±
3. **pgAdmin4** ile veritabanÄ± gÃ¶rsel olarak yÃ¶netildi
4. **Python scriptleri** `.env` dosyasÄ±ndaki ayarlarla veritabanÄ±na baÄŸlandÄ±
5. **TÃ¼m veriler** PostgreSQL'de saklandÄ± ve analiz edildi

**SonuÃ§:** 1155 valid makale `all_valid_articles` tablosunda saklandÄ± ve tÃ¼m analizler bu tablo Ã¼zerinden yapÄ±ldÄ±.

---

## Task 1: Data Collection (Veri Toplama)

### 1.1 NewsAPI Veri Toplama
**Script:** `scripts/collect_newsapi.py`
- **AmaÃ§:** NewsAPI kullanarak CE ve AI konulu haber makalelerini toplama
- **Ã–zellikler:**
  - NewsAPI "everything" endpoint kullanÄ±mÄ±
  - CE ve AI keyword kombinasyonlarÄ± ile arama
  - Metadata toplama (title, publication_date, source, url, description)
  - CSV formatÄ±nda kayÄ±t
- **Ã‡Ä±ktÄ±:** `data/newsapi_articles_*.csv`

### 1.2 Guardian API Veri Toplama
**Script:** `scripts/collect_guardian.py`
- **AmaÃ§:** Guardian Open Platform API ile makale toplama
- **Ã–zellikler:**
  - Guardian API kullanÄ±mÄ±
  - Full text extraction (trafilatura)
  - Strict filtreleme (minimum 1 CE + 1 AI keyword)
  - API limit korumasÄ±
- **Ã‡Ä±ktÄ±:** `data/guardian_articles_*.csv`

### 1.3 RSS Feed Toplama
**Script:** `scripts/collect_rss.py`
- **AmaÃ§:** RSS feed'lerden makale toplama
- **Ã–zellikler:**
  - RSS feed parsing
  - Multiple source support
- **Ã‡Ä±ktÄ±:** `data/rss_articles_*.csv`

### 1.4 Corpus Veri Ä°Ã§e Aktarma
**Script:** `scripts/import_corpus_to_db.py`
- **AmaÃ§:** Mevcut corpus verilerini veritabanÄ±na aktarma
- **Ã‡Ä±ktÄ±:** `data/corpus.csv` â†’ Database

---

## Task 2: Text Preprocessing & NLP

### ğŸ“ NLP KÄ±smÄ±nÄ±n Konumu ve DetaylarÄ±

**Ana NLP Scriptleri:**
- `scripts/preprocess_newsapi.py` - Ana preprocessing script
- `scripts/generate_preprocessing_report.py` - Rapor oluÅŸturma
- `scripts/create_cleaned_dataset.py` - Cleaned dataset oluÅŸturma

**NLP Ã‡Ä±ktÄ± DosyalarÄ±:**
- `data/top20_most_frequent_words.csv` - Top 20 kelime listesi
- `data/top20_bigrams.csv` - Top 20 bi-gram listesi
- `data/preprocessing_report.md` - DetaylÄ± preprocessing raporu
- `data/cleaned_dataset.csv` - TemizlenmiÅŸ dataset (1155 makale)

---

### 2.1 NewsAPI Veri Ã–n Ä°ÅŸleme
**Script:** `scripts/preprocess_newsapi.py`
- **Dosya Yolu:** `49X Final/scripts/preprocess_newsapi.py`
- **AmaÃ§:** NewsAPI verilerini temizleme ve Ã¶n iÅŸleme
- **KullanÄ±lan NLP KÃ¼tÃ¼phaneleri:**
  - `nltk` - Tokenization, stopword removal, lemmatization
  - `scikit-learn` - TF-IDF calculation
- **NLP Ä°ÅŸlemleri (SÄ±rayla):**
  1. **Tokenization** - `nltk.word_tokenize()` ve `nltk.sent_tokenize()` kullanÄ±larak
  2. **Normalization** - Lowercasing, punctuation removal, URL/email removal
  3. **Stopword Removal** - NLTK English stopwords + domain-specific stopwords (article, read, more, click, etc.)
  4. **Lemmatization** - `nltk.WordNetLemmatizer()` ile kelimeleri kÃ¶k formuna indirgeme
  5. **N-grams Extraction** - `nltk.ngrams()` ile bigrams ve trigrams Ã§Ä±karÄ±mÄ±
  6. **TF-IDF Calculation** - `sklearn.TfidfVectorizer()` ile term frequency-inverse document frequency hesaplama
- **Fonksiyonlar:**
  - `normalize_text()` - Text normalizasyonu
  - `remove_stopwords()` - Stopword kaldÄ±rma
  - `lemmatize_text()` - Lemmatization
  - `extract_ngrams()` - N-gram Ã§Ä±karÄ±mÄ±
  - `calculate_tfidf()` - TF-IDF hesaplama
- **Ã‡Ä±ktÄ±:** Processed data with `processed_text`, `bigrams`, `trigrams`, `top_tfidf_terms` kolonlarÄ±

### 2.2 Preprocessing RaporlarÄ± OluÅŸturma
**Script:** `scripts/generate_preprocessing_report.py` âœ… YENÄ°
- **Dosya Yolu:** `49X Final/scripts/generate_preprocessing_report.py`
- **AmaÃ§:** Task 2 gereksinimleri iÃ§in preprocessing raporlarÄ± oluÅŸturma
- **Veri KaynaÄŸÄ±:** `all_valid_articles` tablosundan 1155 makale
- **NLP Ä°ÅŸlemleri:**
  - Text birleÅŸtirme (title + description + abstract)
  - Normalization (lowercasing, URL/email removal)
  - Stopword removal (NLTK + domain-specific)
  - Word frequency counting (Counter kullanarak)
  - Bigram extraction ve frequency counting
- **Ã–zellikler:**
  - Top 20 most frequent words hesaplama (stopwords hariÃ§)
  - Top 20 bi-grams hesaplama
  - Markdown formatÄ±nda detaylÄ± rapor
- **Ã‡Ä±ktÄ±lar:**
  - `data/top20_most_frequent_words.csv` - Rank, Word, Frequency kolonlarÄ± ile
  - `data/top20_bigrams.csv` - Rank, Bigram, Frequency kolonlarÄ± ile
  - `data/preprocessing_report.md` - DetaylÄ± preprocessing raporu (markdown formatÄ±nda)
- **Durum:** âœ… KULLANILDI - 1155 makale Ã¼zerinden raporlar oluÅŸturuldu
- **SonuÃ§lar:**
  - Top Word: "market" (598 kez)
  - Top Bigram: "artificial intelligence" (203 kez)

### 2.3 Cleaned Dataset OluÅŸturma
**Script:** `scripts/create_cleaned_dataset.py` âœ… YENÄ°
- **Dosya Yolu:** `49X Final/scripts/create_cleaned_dataset.py`
- **AmaÃ§:** TemizlenmiÅŸ dataset oluÅŸturma (Task 2 gereksinimi)
- **Veri KaynaÄŸÄ±:** `all_valid_articles` tablosundan
- **NLP Ä°ÅŸlemleri:**
  1. Text birleÅŸtirme (title + description + abstract)
  2. Normalization:
     - Lowercasing
     - Punctuation removal
     - URL removal (regex: `r'http\S+|www\.\S+'`)
     - Email removal (regex: `r'\S+@\S+'`)
     - Special characters removal (sadece alphanumeric ve spaces)
  3. Stopword removal:
     - Common English stopwords (the, a, an, and, or, etc.)
     - Domain-specific stopwords (article, read, more, click, subscribe, etc.)
     - Words with length <= 2 characters excluded
- **Ã‡Ä±ktÄ±:** `data/cleaned_dataset.csv` - 1155 makale, temizlenmiÅŸ text ile
- **Kolonlar:**
  - `id`, `title`, `description`, `url`, `source`, `publication_date`
  - `abstract`, `ce_areas`, `ai_technologies`, `cleaned_text`
- **Durum:** âœ… KULLANILDI - Cleaned dataset oluÅŸturuldu
- **Ä°statistikler:**
  - Toplam makale: 1155
  - Ortalama cleaned text uzunluÄŸu: ~560 karakter

### 2.4 AI/CE Filtreleme
**Script:** `scripts/filter_ai_ce_articles.py`
- **AmaÃ§:** Sadece AI ve CE kesiÅŸimini iÃ§eren makaleleri filtreleme
- **Ã‡Ä±ktÄ±:** `data/filtered_ai_ce_articles.csv`

### 2.5 Common Usage Filtreleme
**Script:** `scripts/filter_common_usage.py`
- **AmaÃ§:** Genel kullanÄ±m iÃ§eren makaleleri filtreleme
- **Ã‡Ä±ktÄ±:** `data/common_usage_articles.csv`

---

## Task 3: Categorization & Trend Analysis

### 3.1 Guardian Makale Validasyonu
**Script:** `scripts/validate_guardian_ce_keywords.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Guardian makalelerinde CE keyword'lerinin geÃ§erliliÄŸini LLM ile kontrol etme
- **YÃ¶ntem:** OpenAI GPT-3.5-turbo API
- **Durum:** KullanÄ±ldÄ±, validasyon yapÄ±ldÄ±, sonra daha esnek versiyonla deÄŸiÅŸtirildi
- **Ã‡Ä±ktÄ±:** `data/guardian_ce_keyword_validation.csv`

**Script:** `scripts/revalidate_guardian_flexible.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Daha esnek kriterlerle Guardian makalelerini yeniden validasyon
- **DeÄŸiÅŸiklik:** Daha dÃ¼ÅŸÃ¼k confidence threshold, daha geniÅŸ CE yorumu
- **Durum:** KullanÄ±ldÄ±, daha fazla valid makale bulundu, iÅŸlevi tamamlandÄ±
- **Ã‡Ä±ktÄ±:** `data/guardian_ce_keyword_validation_flexible.csv`

**Script:** `scripts/save_guardian_valid.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Valid Guardian makalelerini ayrÄ± CSV'ye kaydetme
- **Durum:** KullanÄ±ldÄ±, valid makaleler kaydedildi, iÅŸlevi tamamlandÄ±
- **Ã‡Ä±ktÄ±:** `data/guardian_valid.csv`

### 3.2 Corpus Makale Validasyonu
**Script:** `scripts/validate_corpus_ce.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Corpus makalelerini LLM ile validasyon
- **Durum:** KullanÄ±ldÄ±, corpus makaleleri validate edildi, iÅŸlevi tamamlandÄ±
- **Ã‡Ä±ktÄ±:** `data/corpus_valid.csv`

### 3.3 NewsAPI Makale Validasyonu
**Script:** `scripts/validate_newsapi_flexible.py`
- **AmaÃ§:** NewsAPI makalelerini esnek kriterlerle validasyon
- **YÃ¶ntem:** LLM-based validation
- **Ã‡Ä±ktÄ±:** `data/newsapi_validation_flexible.csv`

**Script:** `scripts/validate_newsapi_comprehensive_flexible.py`
- **AmaÃ§:** KapsamlÄ± ve esnek NewsAPI validasyonu
- **Ã‡Ä±ktÄ±:** `data/newsapi_validation_comprehensive.csv`

**Script:** `scripts/validate_newsapi_ce_ai_intersection.py`
- **AmaÃ§:** NewsAPI makalelerinde CE ve AI kesiÅŸimini kontrol etme
- **Ã‡Ä±ktÄ±:** `data/newsapi_ce_ai_validation.csv`

**Script:** `scripts/validate_newsapi_ai_ce_intersection.py`
- **AmaÃ§:** AI ve CE kesiÅŸimini ters yÃ¶nden kontrol
- **Ã‡Ä±ktÄ±:** `data/newsapi_ai_ce_validation.csv`

**Script:** `scripts/create_newsapi_valid_from_validation.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Validasyon sonuÃ§larÄ±ndan valid NewsAPI makalelerini oluÅŸturma
- **Durum:** KullanÄ±ldÄ±, valid NewsAPI makaleleri oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **Ã‡Ä±ktÄ±:** `data/newsapi_valid.csv`

### 3.4 Dictionary-Based Classification
**Script:** `scripts/classify_ce_ai.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Dictionary-based CE ve AI sÄ±nÄ±flandÄ±rmasÄ±
- **YÃ¶ntem:** Keyword matching
- **Durum:** KullanÄ±ldÄ±, test edildi, sonra LLM-based versiyonla deÄŸiÅŸtirildi
- **CE Areas:** Structural, Geotechnical, Transportation, Construction Management, Environmental Engineering
- **AI Technologies:** Computer Vision, Predictive Analytics, Generative Design, Robotics/Automation
- **Ã‡Ä±ktÄ±:** `data/articles_tagged.csv`

### 3.5 LLM-Based Classification
**Script:** `scripts/classify_ce_ai_llm.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** LLM API kullanarak daha doÄŸru sÄ±nÄ±flandÄ±rma
- **YÃ¶ntem:** OpenAI GPT-3.5-turbo
- **Durum:** KullanÄ±ldÄ±, tÃ¼m makaleler (NewsAPI, Guardian, Corpus) sÄ±nÄ±flandÄ±rÄ±ldÄ±, iÅŸlevi tamamlandÄ±
- **Ã–zellikler:**
  - Her makale iÃ§in CE areas ve AI technologies tagleme
  - Confidence scoring
  - NewsAPI, Guardian, Corpus verilerini iÅŸleme
- **Ã‡Ä±ktÄ±:** `data/articles_tagged_llm.csv`, `data/articles_tagged_llm_complete.csv`
- **Not:** TÃ¼m makaleler baÅŸarÄ±yla sÄ±nÄ±flandÄ±rÄ±ldÄ± ve sonuÃ§lar veritabanÄ±na aktarÄ±ldÄ±. Ä°ÅŸlevi tamamlandÄ±ktan sonra temizlik sÄ±rasÄ±nda silindi.

**Script:** `scripts/retag_untagged_articles.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** TaglenmemiÅŸ makaleleri yeniden tagleme
- **Durum:** KullanÄ±ldÄ±, eksik tag'ler tamamlandÄ±, tÃ¼m valid makalelerin en az 1 CE ve 1 AI tag'i olduÄŸu garanti edildi
- **Ã–zellik:** TÃ¼m valid makalelerin en az 1 CE ve 1 AI tag'i olmasÄ±nÄ± saÄŸlama

### 3.6 Classification Analysis
**Script:** `scripts/classify_and_analyze.py`
- **AmaÃ§:** SÄ±nÄ±flandÄ±rma sonuÃ§larÄ±nÄ± analiz etme
- **Ã‡Ä±ktÄ±lar:**
  - `data/classification_analysis.csv`
  - `data/heatmap_ce_ai.png`
  - `data/bar_chart_*.png`

**Script:** `scripts/generate_classification_report.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** SÄ±nÄ±flandÄ±rma raporu oluÅŸturma
- **Durum:** KullanÄ±ldÄ±, rapor oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **Ã‡Ä±ktÄ±:** `data/classification_report.md`

---

## Task 4: Visualization & Insights

### 4.1 Co-occurrence Heatmaps
**Script:** `scripts/create_normalized_ce_ai_heatmap.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Normalize edilmiÅŸ CE Ã— AI co-occurrence heatmap
- **Durum:** KullanÄ±ldÄ±, heatmap oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **Ã–zellikler:**
  - Row-wise normalization
  - Percentage annotations
- **Ã‡Ä±ktÄ±:** `data/heatmap_ce_ai_specialization_LQ.png`, `data/ce_ai_cooccurrence_normalized.csv`

**Script:** `scripts/create_dual_ce_ai_heatmaps.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Hem raw counts hem normalized percentages iÃ§in dual heatmaps
- **Durum:** KullanÄ±ldÄ±, her iki heatmap oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **Ã‡Ä±ktÄ±lar:**
  - `data/heatmap_ce_ai_raw_counts.png`
  - `data/heatmap_ce_ai_normalized.png`
  - `data/ce_ai_cooccurrence_raw_counts.csv`
  - `data/ce_ai_cooccurrence_normalized.csv`

### 4.2 Temporal Analysis
**Script:** `scripts/time_series_analysis.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Makale hacminin zaman serisi analizi
- **Durum:** KullanÄ±ldÄ±, zaman serisi analizi yapÄ±ldÄ±, gÃ¶rselleÅŸtirme oluÅŸturuldu
- **Ã–zellikler:**
  - GÃ¼nlÃ¼k/haftalÄ±k aggregasyon
  - Rolling average (7-day/14-day)
  - Otomatik spike detection (z-score based)
- **Ã‡Ä±ktÄ±lar:**
  - `data/time_series_total_articles_with_rolling_avg.png`
  - `data/time_series_article_counts.csv`

**Script:** `scripts/temporal_trends_analysis.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Belirli CEÃ—AI kombinasyonlarÄ±nÄ±n temporal trendleri
- **Durum:** KullanÄ±ldÄ±, temporal trendler analiz edildi, iÅŸlevi tamamlandÄ±
- **Ã‡Ä±ktÄ±:** `data/temporal_trends.csv`, `data/temporal_trends.png`

### 4.3 Bump Chart
**Script:** `scripts/create_bump_chart_combinations.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Top 10 CEÃ—AI kombinasyonlarÄ±nÄ±n rank evrimi
- **Durum:** KullanÄ±ldÄ±, bump chart oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **Ã–zellikler:**
  - AylÄ±k rank hesaplama
  - Bump chart visualization
- **Ã‡Ä±ktÄ±lar:**
  - `data/bump_chart_top10_combinations.png`
  - `data/combination_rank_over_time.csv`

### 4.4 Emergence Analysis
**Script:** `scripts/create_emergence_scatter.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** YÃ¼kselen CEÃ—AI kombinasyonlarÄ±nÄ± belirleme
- **Durum:** KullanÄ±ldÄ±, emergence analizi yapÄ±ldÄ±, scatter plot oluÅŸturuldu
- **Ã–zellikler:**
  - x-axis: Recency (ilk gÃ¶rÃ¼nÃ¼mden bu yana geÃ§en gÃ¼n)
  - y-axis: Growth rate (son dÃ¶nem vs Ã¶nceki dÃ¶nem)
  - Point size: Total article count
- **Ã‡Ä±ktÄ±lar:**
  - `data/emergence_scatter_recency_vs_growth.png`
  - `data/emergence_metrics_combinations.csv`

### 4.5 Long-tail Distribution Analysis
**Script:** `scripts/analyze_longtail_distribution.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** CEÃ—AI kombinasyonlarÄ±nÄ±n long-tail daÄŸÄ±lÄ±mÄ±nÄ± analiz etme
- **Durum:** KullanÄ±ldÄ±, long-tail analizi yapÄ±ldÄ±, log-log plot oluÅŸturuldu
- **Ã–zellikler:**
  - Log-log plot
  - Power-law reference line
  - Pareto analysis
- **Ã‡Ä±ktÄ±lar:**
  - `data/loglog_pareto_combination_frequency.png`
  - `data/combination_frequency_ranked.csv`

### 4.6 Source Analysis
**Script:** `scripts/create_source_combination_heatmap.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Hangi kaynaklarÄ±n hangi CEÃ—AI kombinasyonlarÄ±nÄ± kapsadÄ±ÄŸÄ±nÄ± gÃ¶sterme
- **Durum:** KullanÄ±ldÄ±, source analysis heatmap oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **Ã‡Ä±ktÄ±lar:**
  - `data/heatmap_source_by_combination.png`
  - `data/source_combination_matrix.csv`

### 4.7 Word Clouds
**Script:** `scripts/create_wordclouds_by_ce_area.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Her CE alanÄ± iÃ§in AI-filtreli word cloud'lar
- **Durum:** KullanÄ±ldÄ±, 5 CE area iÃ§in word cloud'lar oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **Ã–zellikler:**
  - Her CE area iÃ§in ayrÄ± word cloud
  - AI keyword'leri iÃ§eren makalelerden oluÅŸturuldu
  - Minimum article count kontrolÃ¼
  - High resolution (dpi >= 200)
- **Ã‡Ä±ktÄ±lar:**
  - `data/wc_structural_ai.png`
  - `data/wc_geotechnical_ai.png`
  - `data/wc_transportation_ai.png`
  - `data/wc_construction_mgmt_ai.png`
  - `data/wc_environmental_ai.png`
  - `data/top_terms_*.csv` (her CE area iÃ§in)

**Script:** `scripts/create_ai_wordclouds_and_contrast.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Her AI teknolojisi iÃ§in CE-filtreli word cloud'lar ve contrastive word clouds
- **Durum:** KullanÄ±ldÄ±, 4 AI tech + 2 contrastive word cloud oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **Ã–zellikler:**
  - Her AI tech iÃ§in ayrÄ± word cloud
  - CE keyword'leri iÃ§eren makalelerden oluÅŸturuldu
  - Contrastive word clouds (Transportation+AI vs Structural+AI, Construction Mgmt+AI vs Environmental+AI)
  - TF-IDF difference kullanarak distinctive terms
- **Ã‡Ä±ktÄ±lar:**
  - `data/wc_cv_in_ce.png`
  - `data/wc_predictive_in_ce.png`
  - `data/wc_genai_in_ce.png`
  - `data/wc_robotics_in_ce.png`
  - `data/wc_contrast_transport_vs_structural.png`
  - `data/wc_contrast_conmgmt_vs_env.png`
  - `data/top_terms_*.csv` (her AI tech iÃ§in)
  - `data/contrast_*.csv` (contrastive terms)

**Script:** `scripts/create_ce_area_top_terms_csv.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** CE area word cloud'larÄ± iÃ§in top terms CSV'leri oluÅŸturma
- **Durum:** KullanÄ±ldÄ±, CSV'ler oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **Ã‡Ä±ktÄ±:** `data/top_terms_*.csv`

### 4.8 Network Graphs
**Script:** `scripts/create_keyword_network_graphs.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Keyword co-occurrence network grafikleri
- **Durum:** KullanÄ±ldÄ±, 3 network graph oluÅŸturuldu (full, CE-only, bipartite), iÅŸlevi tamamlandÄ±
- **Ã–zellikler:**
  - Full keyword network (CE + AI together)
  - CE-only keyword network
  - Bipartite network (CE keywords â†” AI keywords only)
  - Community detection (Louvain algorithm)
  - Centrality measures (degree, betweenness)
  - Hub ve bridge node identification
- **Ã‡Ä±ktÄ±lar:**
  - `data/network_full_keywords.png`
  - `data/network_ce_only.png`
  - `data/network_bipartite_ce_to_ai.png`
  - `data/network_metrics_full.csv`
  - `data/network_metrics_ce.csv`
  - `data/network_metrics_bipartite.csv`
  - `data/network_top_bridges.csv`
  - `data/network_insights.txt`

### 4.9 Specialization Analysis
**Script:** `scripts/analyze_ai_specialization_lq.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Location Quotient (LQ) kullanarak AI teknolojilerinin CE alanlarÄ±na Ã¶zelleÅŸmesini analiz etme
- **Durum:** KullanÄ±ldÄ±, LQ analizi yapÄ±ldÄ±, heatmap oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **FormÃ¼l:** LQ = (share of AI within CE) / (overall share of AI)
- **Yorum:** LQ > 1 = CE domain is over-represented for that AI tech
- **Ã‡Ä±ktÄ±lar:**
  - `data/heatmap_ce_ai_specialization_LQ.png`
  - `data/ce_ai_location_quotient.csv`

### 4.10 AI Maturity Ranking
**Script:** `scripts/rank_ce_areas_by_ai_maturity.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** CE alanlarÄ±nÄ± AI olgunluÄŸu/ilgi dÃ¼zeyine gÃ¶re sÄ±ralama
- **Durum:** KullanÄ±ldÄ±, final ranking analizi yapÄ±ldÄ±, gÃ¶rselleÅŸtirme oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **Metrikler:**
  - Article Volume (30%)
  - AI Diversity (25%)
  - Specialization/LQ (25%)
  - Growth Trend (20%)
- **Ã‡Ä±ktÄ±lar:**
  - `data/ce_ai_maturity_ranking.csv`
  - `data/ce_ai_maturity_ranking.png`

---

## Database Management

### 5.1 Database Migration
**Script:** `scripts/migrate_to_postgres.py`
- **AmaÃ§:** SQLite'den PostgreSQL'e veri migrasyonu
- **Ã–zellikler:**
  - Connection pooling
  - Batch processing

### 5.2 NewsAPI Database Import
**Script:** `scripts/import_newsapi_csv_to_db.py`
- **AmaÃ§:** NewsAPI CSV dosyalarÄ±nÄ± veritabanÄ±na aktarma
- **Tablo:** `newsapi_articles`

### 5.3 Valid Articles Database Operations
**Script:** `scripts/save_valid_newsapi_to_db.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Valid NewsAPI makalelerini ayrÄ± tabloya kaydetme
- **Durum:** KullanÄ±ldÄ±, valid NewsAPI makaleleri kaydedildi, iÅŸlevi tamamlandÄ±
- **Tablo:** `newsapi_valid`

**Script:** `scripts/merge_all_valid_to_db.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** TÃ¼m valid makaleleri (NewsAPI, Guardian, Corpus) birleÅŸtirme
- **Durum:** KullanÄ±ldÄ±, tÃ¼m kaynaklar birleÅŸtirildi, unified table oluÅŸturuldu
- **Tablo:** `all_valid_articles`
- **Ã–zellikler:**
  - Column standardization
  - Date format conversion

**Script:** `scripts/add_abstracts_to_unified_table.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Ã–nceki tablolardan abstract'leri birleÅŸtirilmiÅŸ tabloya ekleme
- **Durum:** KullanÄ±ldÄ±, abstract'ler eklendi, iÅŸlevi tamamlandÄ±

**Script:** `scripts/remove_duplicates_from_unified_table.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** URL ve title'a gÃ¶re duplicate'leri kaldÄ±rma
- **Durum:** KullanÄ±ldÄ±, duplicate'ler temizlendi, iÅŸlevi tamamlandÄ±
- **YÃ¶ntem:** URL ve title kombinasyonuna gÃ¶re, sonra URL'e gÃ¶re, sonra title'a gÃ¶re

**Script:** `scripts/generate_abstracts_for_unified_table.py` âœ… KULLANILDI (sonra silindi)
- **AmaÃ§:** Abstract'i olmayan makaleler iÃ§in LLM ile abstract oluÅŸturma
- **Durum:** KullanÄ±ldÄ±, eksik abstract'ler LLM ile oluÅŸturuldu, iÅŸlevi tamamlandÄ±
- **YÃ¶ntem:** OpenAI GPT-3.5-turbo

### 5.4 Database Cleanup
**Script:** `scripts/remove_columns_from_unified_table.py`
- **AmaÃ§:** Gereksiz kolonlarÄ± kaldÄ±rma
- **KaldÄ±rÄ±lan kolonlar:**
  - `text_content`
  - `validation_confidence`
  - `validation_reason`
  - `is_valid`
  - `created_at`
  - `use_case_topic`
  - `topic_confidence`
  - `topic_reason`
  - `source_type`

**Script:** `scripts/reorder_columns_id_first.py`
- **AmaÃ§:** ID kolonunu tablonun baÅŸÄ±na alma
- **YÃ¶ntem:** Tablo yeniden oluÅŸturma

**Script:** `scripts/complete_missing_abstracts_and_renumber_ids.py`
- **AmaÃ§:** 
  1. Eksik abstract'leri tamamlama (LLM ile)
  2. ID'leri 1'den baÅŸlayarak yeniden numaralandÄ±rma
- **SonuÃ§:** 1155 makale, ID'ler 1-1155 arasÄ±

---

## Final Data Preparation

### 6.1 Duplicate Detection
**Script:** `scripts/detect_duplicates_by_summary.py`
- **AmaÃ§:** Summary-based duplicate detection
- **Ã‡Ä±ktÄ±:** `data/duplicate_articles_by_summary.csv`

### 6.2 Abstract Generation
**Script:** `scripts/add_abstracts.py`
- **AmaÃ§:** Makaleler iÃ§in abstract oluÅŸturma
- **YÃ¶ntem:** LLM API

**Script:** `scripts/add_abstracts_filtered.py`
- **AmaÃ§:** FiltrelenmiÅŸ makaleler iÃ§in abstract oluÅŸturma

**Script:** `scripts/add_summaries_newsapi.py`
- **AmaÃ§:** NewsAPI makaleleri iÃ§in summary ekleme

---

## ğŸ“Š Final Database Structure

### `all_valid_articles` Tablosu

**Kolonlar (15 adet):**
1. `id` (integer, PRIMARY KEY) - 1'den baÅŸlayarak sÄ±ralÄ±
2. `title` (text)
3. `description` (text)
4. `url` (text)
5. `source` (text)
6. `publication_date` (timestamp)
7. `ce_keywords_found` (text)
8. `ai_keywords_found` (text)
9. `ce_areas` (ARRAY) - CE alanlarÄ± listesi
10. `ce_confidence` (double precision)
11. `ce_reason` (text)
12. `ai_technologies` (ARRAY) - AI teknolojileri listesi
13. `ai_confidence` (double precision)
14. `ai_reason` (text)
15. `abstract` (text)

**Toplam KayÄ±t:** 1155 makale

### Task 2: Preprocessing Ã‡Ä±ktÄ±larÄ± âœ…

**Cleaned Dataset:**
- `data/cleaned_dataset.csv` - 1155 makale, temizlenmiÅŸ text ile
- Her makale iÃ§in: id, title, description, url, source, publication_date, abstract, ce_areas, ai_technologies, cleaned_text

**Preprocessing RaporlarÄ±:**
- Top 20 most frequent words: market (598), data (451), technology (395), intelligence (280), infrastructure (226)
- Top 20 bi-grams: artificial intelligence (203), data center (97), machine learning (60), deep learning (45)

---

## ğŸ¯ Proje SonuÃ§larÄ± Ã–zeti

### CE Areas - AI Maturity Ranking (Final)
1. **Construction Management** - 97.4/100
2. **Transportation** - 80.8/100
3. **Structural** - 79.7/100
4. **Environmental Engineering** - 73.7/100
5. **Geotechnical** - 65.7/100

### Key Insights
- **En YÃ¼ksek AI OlgunluÄŸu:** Construction Management (686 makale, 4/4 AI teknolojisi)
- **En YÃ¼ksek Ã–zelleÅŸme:** Structural (Avg LQ: 1.095)
- **En Dengeli:** Transportation (yÃ¼ksek hacim + Ã¶zelleÅŸme dengesi)
- **En DÃ¼ÅŸÃ¼k Hacim:** Geotechnical (10 makale)

---

## ğŸ“ Ã–nemli Ã‡Ä±ktÄ± DosyalarÄ±

### Task 2: Preprocessing SonuÃ§larÄ± âœ… YENÄ°
- `data/top20_most_frequent_words.csv` - Top 20 en sÄ±k kullanÄ±lan kelimeler
- `data/top20_bigrams.csv` - Top 20 en sÄ±k kullanÄ±lan bi-gramlar
- `data/preprocessing_report.md` - DetaylÄ± preprocessing raporu
- `data/cleaned_dataset.csv` - TemizlenmiÅŸ dataset (1155 makale)

### Analiz SonuÃ§larÄ±
- `data/ce_ai_maturity_ranking.csv` - AI maturity ranking
- `data/ce_ai_location_quotient.csv` - Location Quotient matrix
- `data/ce_ai_cooccurrence_raw_counts.csv` - Raw co-occurrence counts
- `data/ce_ai_cooccurrence_normalized.csv` - Normalized co-occurrence percentages

### GÃ¶rselleÅŸtirmeler
- `data/heatmap_ce_ai_specialization_LQ.png` - LQ heatmap
- `data/heatmap_ce_ai_raw_counts.png` - Raw counts heatmap
- `data/heatmap_ce_ai_normalized.png` - Normalized heatmap
- `data/ce_ai_maturity_ranking.png` - Ranking bar chart
- `data/time_series_total_articles_with_rolling_avg.png` - Time series
- `data/bump_chart_top10_combinations.png` - Bump chart
- `data/emergence_scatter_recency_vs_growth.png` - Emergence scatter
- `data/loglog_pareto_combination_frequency.png` - Long-tail distribution
- `data/heatmap_source_by_combination.png` - Source analysis
- `data/network_*.png` - Network graphs (3 adet)
- `data/wc_*.png` - Word clouds (9 adet)

---

## ğŸ”§ Teknik Detaylar

### KullanÄ±lan Teknolojiler
- **Python 3.8+**
- **PostgreSQL** (Docker)
- **OpenAI GPT-3.5-turbo API** (LLM classification, validation, abstract generation)
- **Libraries:**
  - `pandas`, `numpy` - Data manipulation
  - `psycopg2` - PostgreSQL connection
  - `openai` - LLM API
  - `matplotlib`, `seaborn` - Visualization
  - `networkx`, `python-louvain` - Network analysis
  - `wordcloud` - Word cloud generation
  - `requests` - API calls
  - `trafilatura` - Web scraping
  - **NLP Libraries:**
    - `nltk` - Tokenization, stopword removal, lemmatization, n-grams
    - `scikit-learn` - TF-IDF calculation (TfidfVectorizer)

### API Keys
- NewsAPI
- Guardian Open Platform API
- OpenAI API

---

## ğŸ“ Notlar

- BazÄ± scriptler silinmiÅŸ veya birleÅŸtirilmiÅŸ olabilir (conversation history'de bahsedilen scriptler)
- TÃ¼m analizler `all_valid_articles` tablosu Ã¼zerinden yapÄ±lmÄ±ÅŸtÄ±r
- LLM API kullanÄ±mÄ± iÃ§in rate limiting uygulanmÄ±ÅŸtÄ±r
- Database connection pooling kullanÄ±lmÄ±ÅŸtÄ±r

---

## ğŸ” NLP KISMI HIZLI REFERANS

### ğŸ“‚ NLP Scriptleri Nerede?
- **Ana Preprocessing:** `scripts/preprocess_newsapi.py`
- **Rapor OluÅŸturma:** `scripts/generate_preprocessing_report.py`
- **Cleaned Dataset:** `scripts/create_cleaned_dataset.py`

### ğŸ“ NLP Ã‡Ä±ktÄ± DosyalarÄ± Nerede?
- **Top 20 Words:** `data/top20_most_frequent_words.csv`
- **Top 20 Bi-grams:** `data/top20_bigrams.csv`
- **Preprocessing Raporu:** `data/preprocessing_report.md`
- **Cleaned Dataset:** `data/cleaned_dataset.csv`

### ğŸ“š NLP KÃ¼tÃ¼phaneleri
- **NLTK:** Tokenization, stopword removal, lemmatization, n-grams
  - `nltk.word_tokenize()` - Kelime tokenization
  - `nltk.sent_tokenize()` - CÃ¼mle tokenization
  - `nltk.corpus.stopwords` - Stopword listesi
  - `nltk.stem.WordNetLemmatizer()` - Lemmatization
  - `nltk.util.ngrams()` - N-gram Ã§Ä±karÄ±mÄ±
- **scikit-learn:** TF-IDF calculation
  - `sklearn.feature_extraction.text.TfidfVectorizer()` - TF-IDF hesaplama

### ğŸ”„ NLP Ä°ÅŸlem AdÄ±mlarÄ± (SÄ±ralÄ±)
1. **Tokenization** - Metni kelimelere/cÃ¼mlelere ayÄ±rma (NLTK word_tokenize)
2. **Normalization** - KÃ¼Ã§Ã¼k harfe Ã§evirme, noktalama kaldÄ±rma, URL/email temizleme
3. **Stopword Removal** - YaygÄ±n kelimeleri kaldÄ±rma (NLTK + domain-specific)
4. **Lemmatization** - Kelimeleri kÃ¶k formuna indirgeme (NLTK WordNetLemmatizer)
5. **N-grams Extraction** - Bigram ve trigram Ã§Ä±karÄ±mÄ± (NLTK ngrams)
6. **TF-IDF Calculation** - Term frequency-inverse document frequency hesaplama (scikit-learn)

### ğŸ“Š NLP SonuÃ§larÄ±
- **Top Word:** market (598 kez)
- **Top Bigram:** artificial intelligence (203 kez)
- **Toplam Ä°ÅŸlenen Makale:** 1155
- **Ortalama Cleaned Text UzunluÄŸu:** ~560 karakter

### ğŸ¯ NLP KullanÄ±m SenaryolarÄ±
- **Preprocessing:** `preprocess_newsapi.py` - Ham metinleri temizleme
- **Rapor OluÅŸturma:** `generate_preprocessing_report.py` - Top 20 words/bi-grams
- **Dataset HazÄ±rlama:** `create_cleaned_dataset.py` - Analiz iÃ§in temiz dataset

---

## ğŸ“Œ Ã–nemli Not: "Silindi" Ä°fadesi HakkÄ±nda

Bu dokÃ¼mantasyonda **"âœ… KULLANILDI (sonra silindi)"** ifadesi ÅŸu anlama gelir:

- âœ… **Script kullanÄ±ldÄ±** - Conversation sÄ±rasÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±ldÄ± ve iÅŸlevini yerine getirdi
- âœ… **Ä°ÅŸlevi tamamlandÄ±** - Gerekli analiz/veri iÅŸleme yapÄ±ldÄ±, Ã§Ä±ktÄ±lar oluÅŸturuldu
- âœ… **Sonra silindi** - Ä°ÅŸlevi tamamlandÄ±ktan sonra temizlik sÄ±rasÄ±nda dosya sisteminden kaldÄ±rÄ±ldÄ±

**Ã–rnekler:**
- `classify_ce_ai_llm.py` â†’ TÃ¼m makaleler sÄ±nÄ±flandÄ±rÄ±ldÄ±, sonuÃ§lar veritabanÄ±na aktarÄ±ldÄ±, script silindi
- `create_wordclouds_by_ce_area.py` â†’ 5 word cloud oluÅŸturuldu, gÃ¶rseller kaydedildi, script silindi
- `rank_ce_areas_by_ai_maturity.py` â†’ Final ranking analizi yapÄ±ldÄ±, gÃ¶rselleÅŸtirme oluÅŸturuldu, script silindi

**HiÃ§ kullanÄ±lmayan scriptler deÄŸildir!** TÃ¼m scriptler conversation sÄ±rasÄ±nda aktif olarak kullanÄ±ldÄ± ve proje sonuÃ§larÄ±na katkÄ± saÄŸladÄ±.

---

**Son GÃ¼ncelleme:** 2025-01-XX
**Proje Durumu:** âœ… TamamlandÄ±

